
In this section we introduce \SLref, which extends \SL 
with nondeterministic strategies,  an \emph{outcome quantifier} that
quantifies over possible outcomes of a strategy profile,
and more importantly, a refining operator that expresses that a
strategy refines another.
We first fix some basic notations.



 \subsection{Syntax}
 \label{sec-SL-definition}

In addition to the sets of propositions $\APf$ and agents $\Agf$, we
now fix $\Varf$, a finite non-empty set of \emph{variables}.



\begin{definition}%[\SLref Syntax]
  \label{def-SLi}
    The syntax of \SLref is defined by the following grammar:
    \begin{align*}
  \phi\egdef &\; p 
  \mid \neg \phi 
  \mid \phi\ou\phi 
               \mid \exists\var \phi
               \mid \var \refines \varb
               \mid \bind{\var}\phi
%               \mid \unbind\phi
  \mid \Eout\psi               
      \\
      \psi\egdef &\; \phi
                   \mid \neg \psi
                   \mid \psi\ou \psi
                   \mid \X \psi
                   \mid  \psi \until \psi
    \end{align*}
     where 
  $p\in\APf$, $\var,\varb\in\Varf$ and $a\in\Agf$.
\end{definition}

Formulas of type $\phi$ are called \emph{state formulas}, those of type $\psi$
are called \emph{path formulas}, and \SLref consists of all state formulas.


Temporal operators, $\X$ (next) and
 $\until$ (until), have the usual meaning. The \emph{refinement
   operator} expresses that the strategy denoted by a variable $\var$ is more
 restrictive than another one or, in other words, that it allows less behaviours: $\var\refines\varb$ reads as ``strategy
 $\var$ refines strategy $\varb$''. The  \emph{strategy
   quantifier}  $\exists\var$  has its usual meaning, except that it now
 quantifies on \emph{nondeterministic}
 strategies: $\exists\var\phi$
 reads as ``there exists a nondeterministic
 strategy $\var$
  such that $\phi$
 holds'', where $\var$ is a strategy variable. 
As usual, the \emph{binding operator} $\bind{\var}$ assigns a strategy to an
 agent, and $\bind{\var}\phi$ reads as ``when agent $\ag$ plays strategy $\var$,
 $\phi$ holds''.
 %The \emph{unbinding operator} $\unbind$
%  instead releases agent
% $\ag$ from her current strategy, if she has one, and
% $\bind{\unb}\phi$ reads as ``when
% agent $\ag$ is not assigned any strategy, $\phi$ holds''. 
Finally, the \emph{outcome quantifier} $\Eout$ quantifies on
   outcomes of strategies currently in use: $\Eout\psi$ reads as ``$\psi$
 holds in some
 outcome of the strategies currently used by the players''.

We use usual abbreviations $\top\egdef p\ou\neg p$, $\perp\egdef\neg\top$, $\phi\impl\phi'\egdef \neg \phi \ou \phi'$,
$\phi\equivaut\phi'\egdef \phi\impl\phi'\et \phi'\impl\phi$,
$\Aout\psi\egdef \neg \Eout \neg\psi$,
 $\F\phi \egdef \top \until \phi$,   $\always\phi \egdef \neg \F
\neg \phi$ and
 $\forall\var\phi\egdef\neg\exists\var\neg\phi$. % and $\Astratd\phi\egdef\neg\Estratd\neg\phi$.

% %\todo{see if still necessary; if so, adapt}
For every formula $\phi\in\SLref$, we let  $\free(\phi)$ be the set of variables that appear
free in $\phi$, \ie, that
appear out of the scope of a strategy quantifier. A formula $\phi$ is a \emph{sentence} if $\free(\phi)$ is empty.
Finally, we let the \emph{size} $|\phi|$ of a formula $\phi$ be the
number of symbols in $\phi$.


\subsection{Semantics}
\label{sec-SLmodels}

 \SLref formulas are interpreted in a \CGS, and the semantics makes
 use of the following additional notions.
% \halfline

% \head{Assignments} 
An \emph{assignment}  $\assign:\Agf\union\Varf \partialto \setstrat$
is a partial function that assigns a strategy  to
each  player and strategy variable in its domain.
For an assignment
$\assign$, player $a$ and  strategy $\strat$,
$\assign[a\mapsto\strat]$ is the assignment of domain
$\dom(\assign)\union\{a\}$ that maps $a$ to $\strat$ and is equal to
$\assign$ on the rest of its domain, and 
$\assign[\var\mapsto \strat]$ is defined similarly, where $\var$ is a
variable. %  also, $\assign[a\mapsto\unb]$ is
 % the restriction of $\assign$ to domain $\dom(\assign)\setminus\{a\}$.
We write $\Agf(\assign)$ for $\dom(\assign)\inter \Agf$, and
$\Varf(\assign)$ for $\dom(\assign)\inter\Varf$.
An assignment is
\emph{variable-complete} for a formula $\phi\in\SLref$ if
 $\free(\phi)\subseteq\Varf(\assign)$.

% \halfline
% \head{Outcomes}
For an assignment $\assign$ and a finite play $\fplay$, we define the
\emph{outcomes of $\assign$ from $\fplay$}
as the set of infinite plays that start with
$\fplay$ and are then extended by letting players follow the strategies
assigned by $\assign$. Formally,
we define $\out(\assign,\fplay)$ as the set of plays of the form $\fplay \cdot
 \pos_{1}\pos_{2}\ldots$ such that for all $i\geq 0$, there exists
 $\jmov$ such that for all $\ag\in\Agf(\assign)$, it holds that
 $\jmov_\ag\in\assign(\ag)(\fplay\cdot\pos_{1}\ldots\pos_i)$ \mbox{ and }
 $\pos_{i+1}=\trans(\pos_{i},\jmov)$, \mbox{ with }
 $\pos_{0}=\last(\fplay)$.
 

\begin{definition}%[\SLi semantics]
\label{def-SLi-semantics}
The semantics of a state formula is defined on a \CGS $\CGS$, an
assignment  $\assign$ that is variable-complete for $\phi$, and a
finite play $\fplay$. For a path formula $\psi$, the finite play is
replaced with an infinite play $\iplay$ and an index $i\in\setn$. The
definition by mutual induction is as follows:
\begingroup
\allowdisplaybreaks
\[
\begin{array}{lcl}
 \CGS,\assign,\fplay\modelsSL p & \text{if} & p\in\val(\last(\fplay))\\[3pt]
 \CGS,\assign,\fplay\modelsSL \neg\phi & \text{if} &
  \CGS,\assign,\fplay\not\modelsSL\phi\\[3pt]
 \CGS,\assign,\fplay\modelsSL \phi\ou\phi' & \text{if} &
  \CGS,\assign,\fplay\modelsSL\phi \;\text{ or }\;
  \CGS,\assign,\fplay\modelsSL\phi' \\[3pt]
 \CGS,\assign,\fplay\modelsSL\exists\var\phi  & \text{if} & 
\exists\,   \strat\in\setstratnd \;\text{s.t.} \;
                                                          \CGS,\assign[\var\mapsto\strat],\fplay\modelsSL
                                                          \phi\\[3pt]
   \CGS,\assign,\fplay\modelsSL \var\refines\varb & \text{if} &
                                                              \assign(\var)
                                                              \mbox{
                                                              refines
                                                                }\assign(\varb)
  \mbox{ after }\fplay\\[3pt]
 \CGS,\assign,\fplay\modelsSL \bind{\var}\phi & \text{if} &
 \CGS,\assign[\ag\mapsto\assign(\var)],\fplay\modelsSL \phi\\[3pt]  
 % \CGS,\assign,\fplay\modelsSL \bind{\unb}\phi & \text{if} &
 %          \CGS,\assign[\ag\mapsto\unb],\fplay\modelsSL \phi\\[3pt]
 \CGS,\assign,\fplay\modelsSL \Eout\psi & \text{if} & \exists\iplay \in
                                                         \out(\assign,\fplay)
                                                         \text{ s.t. }
  \\
  & &\quad   \CGS,\assign,\iplay,|\fplay|-1\modelsSL \psi\\[5pt]
    \CGS,\assign,\iplay,i\modelsSL \phi & \text{if} &
                                                         \CGS,\assign,\iplay_{\leq i}\modelsSL\phi\\[3pt]
   \CGS,\assign,\iplay,i\modelsSL \neg\psi & \text{if} &
  \CGS,\assign,\iplay,i\not\modelsSL\psi\\[3pt]
 \CGS,\assign,\iplay,i\modelsSL \psi\ou\psi' & \text{if} &
  \CGS,\assign,\iplay,i\modelsSL\psi \;\text{ or }\;
  \CGS,\assign,\iplay,i\modelsSL\psi' \\[3pt]
  \CGS,\assign,\iplay,i\modelsSL\X\psi & \text{if} &
  \CGS,\assign,\iplay,i+1\modelsSL\psi\\[3pt]
\CGS,\assign,\iplay,i\modelsSL\psi\until\psi' & \text{if} & \exists\, j\geq i
   \mbox{ s.t. }\CGS,\assign,\iplay,j\modelsSL \psi' \text{ and,}\\ 
   & & \forall\, k \text{ s.t. } i\leq k <j,
\; \CGS,\assign,\iplay,k\modelsSL \psi
\end{array}
\]
\endgroup
\end{definition}


We give some examples of useful notions that can be expressed in this
logic. 

\begin{example}[Strategy equality]
  First, it is easy to see that a strategy $\strat$ refines a strategy
  $\strat'$ if $\strat \refines \strat'$ and
  $\strat'\refines\strat$. We thus define the abbreviation
  \[\var = \varb \quad := \quad \var \refines \varb \wedge \varb
    \refines \var\]
  We thus have that $\CGS,\assign,\fplay\models \var = \varb$ if, and
  only if, $\substrat{\assign(\var)}=\substrat{\assign(\varb)}$. And in
  particular, $\CGS,\assign,\pos_\init\models\var=\varb$ if, and only
  if, $\assign(\var)=\assign(\varb)$.
  We also let $\var \neq \varb := \neg (\var = \varb)$ and
  $\var\refinesstr\varb := \var \refines \varb \wedge \var \neq \varb$.
\end{example}

\begin{example}[Deterministic strategies]
  We can also express that a strategy, or its refinement to
  continuations of the current finite play, is deterministic, with the
  following formula:
  \[\phidet \quad := \quad \forall \varb \; \varb \refines \var \impl \var\refines\varb\]
\end{example}

In the following we will use the following notations to express
quantification on \emph{deterministic} strategies:
\begin{align*}
\existsd\var \phi & :=
\exists\var (\phidet \wedge \phi) \\
\text{and }\quad \foralld \var \phi & := \forall \var (\phidet \rightarrow \phi)
\end{align*}
Note that, as usual, we have $\foralld \var \phi \equiv \neg \existsd\var \neg \phi$.

\subsection{Outcomes as strategy refinements}
\label{sec-link-E-ref}

Before stating our main result, we point out that the outcome
quantifier $\Eout$ is tightly linked to strategy refinement. More
precisely, selecting an individual outcome of an assignment
$\assign$ amounts to choosing a \emph{deterministic} strategy $\strat_\ag$ for each
player $\ag$ such that $\strat_\ag\refines \assign(\ag)$ for each $\ag\in\Agf(\assign)$.
Indeed, fixing a deterministic strategy for each player fixes a unique
play, and the refinement constraint ensures that this play follows the
nondeterministic strategies assigned by $\assign$.

\begin{lemma}
  \label{lem-link-E-ref}
  Let $\psi$ be an \LTL formula, $\CGS$ a \CGS, $\fplay$ a finite play
  in $\CGS$ and $\assign$ an assignment such that
  $\assign(\ag)=\assign(\var_\ag)$ for each $\ag\in\Agf(\assign)$.  It holds
  that
  \begin{align*}
      \CGS,\assign,\fplay &\models\Eout\psi \\
      &\text{iff} \\
    \CGS,\assign,\fplay \models
      \existsd_{\ag\in\Agf} \varb_{\ag}
      \bigwedge_{\ag\in\Agf(\assign)}&\varb_\ag \refines \var_\ag
                          \wedge (\ag,\varb_\ag)_{\ag\in\Agf} \Aout\psi
  \end{align*}
\end{lemma}

Notice that in the last formula, $\Aout\psi$ could be replaced by
$\Eout\psi$: indeed, after each agent $\ag$ has been bound to deterministic
strategy $\varb_\ag$,  there exists a unique outcome.

\subsection{Main result}
\label{sec-main-result}

To state precisely the complexity of model checking \SLref we need the
 notion of simulation depth, introduced in \bam{cite arxiv},
 which is meant to count how many nested simulation procedures have to
 be performed in the automata construction, to change alternating
 automata into nondeterministic ones. The simulation depth
 $\ndd(\phi)$ of a formula $\phi$ is a pair $(k,x)$ where $k$ is the
 number of nested simulations needed in the automata construction for
 $\phi$, and $x\in\{\text{nd},\text{alt}\}$ is the type of automaton
 obtained (nondeterministic or alternating). We write $\ndd_k(\phi)$
 and $\ndd_x(\phi)$ for, respectively, the first and second component of $\ndd(\phi)$.
 The inductive definition is as follows:
      \[
        \begin{array}{l}%
          \ndd(p) \egdef (0,\nd)\\[5pt]
          \ndd(\neg \phi) \egdef \ndd_k(\phi),\alt)\\[5pt]
          \ndd(\phi_1\ou\phi_2) \egdef \left
          (\max_{i\in\{1,2\}}\ndd_k(\phi_i), x \right ),\\[5pt]
          \hfill \mbox{where
          }x=    \begin{cases}
            \nd & \mbox{if }\ndd_x(\phi_1)=\ndd_x(\phi_2)=\nd\\
            \alt & \mbox{otherwise}
          \end{cases}
          \\[5pt]
          \ndd( \exists\var\phi)\egdef (k,\nd),\\[5pt]
          \hfill \mbox{where }
          k=\begin{cases}
            \ndd_k(\phi) & \mbox{if }\ndd_x(\phi)=\nd \\
            \ndd_k(\phi)+1 & \mbox{otherwise}
          \end{cases} \\[5pt]
          \ndd(\bind{\var}\phi) \egdef \ndd(\phi)\\[5pt]
          \ndd(\Eout\psi)\egdef
          \begin{cases}
            (0,\nd) &\mbox{if }\psi\in\LTL\\
            (\max_{\phi\in\max(\psi)}\ndd_k(\phi),\alt) &\mbox{otherwise}
          \end{cases}                                                        
        \end{array}
      \]

We say that a formula $\phi$ has simulation depth $k$ if
$\ndd_k(\phi)=k$.  We now state the following result, which is proved
in Section~\ref{section:mc}.

\begin{theorem}
  \label{theo-SLref}
  Model checking \SLref is $(k+1)$-\EXPTIME-complete for formulas of
  simulation depth at most $k$.
\end{theorem}

In the following sections we  show how \SLref captures a number of
important problems related to strategy synthesis and nondeterministic strategies. 






%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
