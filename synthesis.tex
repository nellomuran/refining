In this section we show how our framework captures generalisations of
the classical \LTL synthesis problem to the context of nondeterministic strategies.

\subsection{Classical LTL synthesis}
\label{sec-ltl-synth}

We first recall the standard LTL synthesis problem as defined
in~\cite{pnueli1989synthesisshort}: consider a set of \emph{input
  variables} $I$ controlled by the environment and a set of
\emph{output variables} $O$ controlled by the system. In each round,
first the environment chooses a valuation of the inputs $i_k\in 2^I$
(called \emph{input}), and then the system reacts by choosing a
valuation on the output variables $o_k\in 2^O$ (called \emph{output});
an infinite word over $2^{I\cup O}$ is called an
\emph{execution}. The system has perfect recall, meaning that its
choices can depend on all previous choices of the environment, and a
strategy for the system is thus a function $S:(2^I)^+\to 2^O$. Given
an infinite sequence of inputs $w=i_0i_1i_2\ldots \in (2^I)^\omega$, we
define the execution $S(w)=i_0\cup o_0, i_1\cup o_1, i_2\cup o_2\ldots$ where,
for each $k\geq 0$, $o_k=S(i_0\ldots i_k)$.

The \emph{LTL synthesis problem} consists in,
given $I$, $O$ and an \LTL formula $\psi$ over atoms $I\cup O$,
synthesising a (finite representation of a) system $S:(2^I)^+\to 2^O$ such
that for all $w=i_0i_1i_2\ldots\in (2^I)^\omega$ it holds that $S(w)\models\psi$.
This problem is known to be
\2EXPTIME-complete~\cite{pnueli1989synthesisshort}, and it can easily
be coded in Strategy Logic: one builds a turn-based game arena $\CGS_{I,O}$ (which
can be represented as a \CGS, see Remark~\ref{rem-turn-based}) with
two players, E (for Environment) and S (for System) in
which first the environment chooses an input $i$, then the system chooses
an output $o$, reaching a position labelled with atoms $i\cup o$ and in which it is
the environment's turn to play. The LTL synthesis problem for $(I,O,\psi)$ can
then be solved by model-checking the \SL formula
\[\phisynth:=\Estratnd (S,\var) \Astratnd[\varb] (E,\varb) \A \psi\]
on $\CGS_{I,O}$, where $\Estratnd$ and $\Astratnd$ are interpreted as
quantification on deterministic strategies. Note that this really solves the synthesis
problem as existing model-checking algorithms for Strategy Logic can
synthesise  witness strategies (when they exist) for strategy variables existentially
quantified at the beginning of the formula.

Note also that in the case of deterministic strategies, fixing a
strategy for each player fixes a unique outcome, and thus $\A\psi$ in
the formula above could be replaced by $\E\psi$ without affecting the semantics.
Also, once a deterministic strategy $\var$ is fixed for $S$, each
deterministic strategy for $E$ fixes an outcome of strategy $\var$, and each outcome
of $\var$ can be obtained by fixing a deterministic strategy $\varb$
for $E$. It then follows by the
semantics of the outcome quantifier $\A$ that, when
considering only deterministic strategies,
$\phisynth$ is equivalent to $\Estratnd(S,\var)\A\psi$.

\subsection{Nondeterministic synthesis}
\label{sec-nd-synth}

Considering nondeterministic strategies, as we do, does not change
anything for classical \LTL synthesis. Indeed, it is a simple exercise
to check that the two interpretations of $\phisynth$, \ie, with
deterministic or nondeterministic strategies, are equivalent.

%the two interpretations of
%  formula $\phisynth$ are equivalent: one direction
% holds because deterministic strategies are a particular case of
% nondeterministic ones, and the other direction holds because if there
% exists a nondeterministic strategy $\strat$ such that $(S,\var)
% \Astratnd[\varb] (E,\varb)\A\psi$
% holds when $\var$ is evaluated to $\strat$, then all outcomes of
% $[S\mapsto \strat]$ satisfy $\psi$, and it is thus also the case when $\strat$
% is replaced by any deterministic strategy $\strat'$ that refines
% $\strat$ and thus generates a subset of its outcomes.

However it makes a difference if, instead of considering only
universal satisfaction of an \LTL formula on all outcomes, we consider
other forms of branching-time specifications, in particular
specifications that require existence of outcomes satisfying different
properties. For instance,
\[\phi_1:=\Estratnd (S,\var) \Astratnd[\varb] (E,\varb) (\E \always p \wedge \E \F \neg p)\] 
is always false with the deterministic semantics, because a pair of
strategies for the system and the environment determine a unique
outcome that cannot satisfy both $\always p$ and $\F\neg p$.
However it can be true with the
nondeterministic interpretation.
\bam{write example of model where it holds}

Then we can combine the two kinds of specifications by  requiring the
existence of behaviours satisfying some properties, while requiring
that all  behaviours satisfy some other property.
For instance, formula
\[\phi_2:=\Estratnd (S,\var) \Astratnd[\varb] (E,\varb)(\E \F p \wedge \E \F
  q \wedge \A \always \F (p\vee q))\]
  asks that some behaviours 
 reach $p$, some  reach $q$, and all behaviours go infinitely
 often through $p$ or $q$.

It is then natural to look for  strategies that allow for as many
behaviours as possible. Such strategies are usually called
\emph{maximally permissive} in the litterature.

\bam{this is in 2\EXPTIME}

\subsection{Maximally permissive synthesis}
\label{sec-max-perm}

Different definitions of maximal permissive strategies have been used
in the literature. In supervisory control
theory~\cite{ramadge1987supervisory}, maximality is expressed in terms
of inclusion of sets of behaviours/outcomes, or equivalently by
referring to simulation between the unfoldings of the systems where
unauthorised transitions have been pruned, as
in~\cite{pinchinat2005you}.  In~\cite{bernet2002permissive},
strategies are also compared by looking at inclusion of the behaviours
(outcomes) they allow. However, as it is proved
in~\cite{bernet2002permissive}, the existence of maximally permissive
strategies for this notion of maximality is ensured only for simple
safety games.

For this reason an alternative notion of strategy
permissiveness was introduced in~\cite{bouyer2009measuring} for
reachability games and further studied in~\cite{bouyer2011measuring}
for parity games. In this setting, to each transition in a game is
attached a cost that represents the penalty incurred by a strategy
that does not allow this transition, and a maximally permissive
strategy is one that minimises penalties.

The latter definition ensures that
maximally permissive strategies always exist, but the quantitative
aspects involved, which are close to mean-payoff
games~\cite{ehrenfeucht1979positional,gurvich1988cyclic}, are known to
quickly lead to undecidability when introduced in Strategy Logic~\cite{gardy2017semantics}.
As for the definition based on inclusion of outcomes, it makes sense in the
two-player antagonistic setting; but in our multi-player setting, where the set of
outcomes induced by a strategy depends on which agent uses it, and
which other agents have a defined strategy, it is not so meaningful.

For this reason we naturally define permissiveness based on refinement
of strategies: $\sigma'$ is at least as permissive as $\sigma$ if $\sigma\refines\sigma'$.
With this definition, given a formula $\phi(\var)$ we can express that a strategy $\var$
  is maximally permissive with regards to  $\phi(\var)$. Define formula $\maxperm(\var,\phi)$ as
  follows:
  \[\maxperm(\var,\phi) \quad := \quad \phi(\var) \wedge (\forall \varb \;
    \var \refinesstr \varb \impl \neg \phi(\varb))\]
  For instance, if we have two antagonistic players $\ag$ and $\agb$,
  and $\ag$ tries to ensure the safety property $\always p$, we can let $\phi(\var)=\forall \varc
  \bind[\ag]{\var}\bind[\agb]{\varc}\A\always p$, and it then holds that
  $\CGS,\assign,\pos_\init\models \maxperm(\var,\phi)$ if, and only
  if, $\assign(\var)$ is a maximally permissive winning strategy for $\ag$.

To solve the problem of existence of maximally permissive strategy for
agent $\ag$ and objective $\phi\in\CTLs$,  we can thus model-check the
following \SLref formula:

\[\Estratnd (\ag,\var) \maxperm(\var,\phi)\]

When the formula is true, our model-checking algorithm can also
produce a witness strategy for $\var$ that is maximally permissive.
%In particular, the above formula is always true when  $\phi$ encodes a safety objective.

\bam{this is in 3\EXPTIME}

\subsection{Plan B}
\label{sec-plan-B}

A problem that has been much studied in AI \bam{references needed} is
that of producing plans that enforce some safety property, and in addition
can at any time be refined to reach some secondary goal. For instance,
consider an electric vehicle transporting rocks from a point A, where
they are cut, to a point B, where they are used. The truck must ensure
that the stock of rocks at point B never runs out (safety property). We would like to synthesise a
strategy for the truck such that  this property is satisfied, but also
so that at any time, the strategy can be refined to make the truck go
through point C, where its battery can be reloaded.
We can express  this problem in \SLref as follows, where ``empty''
holds when there are no more rocks in point B, and ``reload'' means
that the truck is at point C, reloading its battery.

\[\Estratnd (\text{truck},\var) \A \always \left ( \neg \text{empty} \wedge
  (\Estratnd[\varb] \varb\refines\var \wedge (\text{truck},\varb)\A\F \text{reload}) \right )\]

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
